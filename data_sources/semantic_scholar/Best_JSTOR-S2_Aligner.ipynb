{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64206f8e-7939-42ad-818a-2b0ce9ef7c96",
   "metadata": {},
   "source": [
    "# Improved JSTOR-S2 Aligner\n",
    "\n",
    "The code in this notebook aligns JSTOR articles with Semantic Scholar, using both the title and the doi as evidence. \n",
    "\n",
    "Our strategy:\n",
    "\n",
    "1. Do a search query on title keywords in Semantic Scholar.\n",
    "2. Iterate through results to find the best match with author and publication date, as well as title and journal title. \n",
    "3. If there's also a match to the DOI recorded in JSTOR, we record that as well, and trust it more.\n",
    "4. We select the paper with highest trust. Generally if we found the DOI, this is that paper. Otherwise, if the search had a trust score of higher than 0.7, it's the searched paper. Note: papers with marginal trust scores of less than 0.85 might still not be very reliable matches. We should check some.\n",
    "4. In recording citations, we check the second page of results if there's more than 1000.\n",
    "\n",
    "In checking names, we only consider last names because format of first names and initials is volatile.\n",
    "\n",
    "#### How to use it\n",
    "\n",
    "Run all the cells down to \"Match A Segment,\" so the code is in memory. Load the appropriate metadata file for your discipline.\n",
    "\n",
    "Then use the function match_a_segment() to step through the metadata file in reasonable-sized chunks. I'm guessing a reasonable chunk is around 4000 or 5000 rows at a time.\n",
    "\n",
    "So you might run\n",
    "\n",
    "match_a_segment(inmeta, 0, 5000, 'econ')\n",
    "\n",
    "and then\n",
    "\n",
    "match_a_segment(inmeta, 5000, 10000, 'econ')\n",
    "\n",
    "When you're done with the whole metadata file, the function concatenate_results() at the end will concatenate all the result files you produced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9db4f6-e643-44cc-a9ca-7dd1d9e1b597",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dd0a2caa-eeb7-4a29-975d-e1204f2088b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib, urllib.request\n",
    "import requests\n",
    "import time, re\n",
    "import json, glob\n",
    "from difflib import SequenceMatcher\n",
    "from ast import literal_eval\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eaae8d-2e82-4a4c-ad83-6cc6811fb618",
   "metadata": {},
   "source": [
    "### get api key\n",
    "\n",
    "It's good practice not to save private keys in the github repo.\n",
    "\n",
    "Instead we'll share the S2 api key as a one-line text file that we place in the same directory as this script, and do not add to git. I need to email it to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9be1deaa-490c-4cd5-9c63-0c92446112b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('apikey.txt', encoding = 'utf-8') as f:\n",
    "    apikey = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb56c1f-1f4f-4b62-87a0-08c2a934e8b4",
   "metadata": {},
   "source": [
    "### Create metadata file for a discipline\n",
    "\n",
    "If JSTOR provides good full metadata, which they seem to have done for Sarah's Econ corpus, this is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08106204-2611-4d7c-8570-c823c13a8ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>isPartOf</th>\n",
       "      <th>publicationYear</th>\n",
       "      <th>doi</th>\n",
       "      <th>docType</th>\n",
       "      <th>docSubType</th>\n",
       "      <th>provider</th>\n",
       "      <th>collection</th>\n",
       "      <th>datePublished</th>\n",
       "      <th>...</th>\n",
       "      <th>creator</th>\n",
       "      <th>publisher</th>\n",
       "      <th>language</th>\n",
       "      <th>pageStart</th>\n",
       "      <th>pageEnd</th>\n",
       "      <th>placeOfPublication</th>\n",
       "      <th>keyphrase</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>pageCount</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.jstor.org/stable/44955205</td>\n",
       "      <td>SUBMISSION OF MANUSCRIPTS TO THE ECONOMETRIC S...</td>\n",
       "      <td>Econometrica</td>\n",
       "      <td>2018</td>\n",
       "      <td>10.2307/44955205</td>\n",
       "      <td>article</td>\n",
       "      <td>misc</td>\n",
       "      <td>jstor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Jeffrey C. Ely; Donald W. K. Andrews</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>eng</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pdf format; electronic submissions; manuscript...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1</td>\n",
       "      <td>part-1.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.jstor.org/stable/1808822</td>\n",
       "      <td>New Books</td>\n",
       "      <td>The American Economic Review</td>\n",
       "      <td>1933</td>\n",
       "      <td>10.2307/1808822</td>\n",
       "      <td>article</td>\n",
       "      <td>research-article</td>\n",
       "      <td>jstor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1933-03-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Economic Association</td>\n",
       "      <td>eng</td>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kartelle berlin; heymanns verlag; carl heymann...</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2</td>\n",
       "      <td>part-1.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.jstor.org/stable/1924813</td>\n",
       "      <td>U.S. Evidence on Linear Feedback from Money Gr...</td>\n",
       "      <td>The Review of Economics and Statistics</td>\n",
       "      <td>1985</td>\n",
       "      <td>10.2307/1924813</td>\n",
       "      <td>article</td>\n",
       "      <td>research-article</td>\n",
       "      <td>jstor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985-11-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Mary G. McGarvey</td>\n",
       "      <td>The MIT Press</td>\n",
       "      <td>eng</td>\n",
       "      <td>675</td>\n",
       "      <td>680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relative price; feedback; growth shocks; money...</td>\n",
       "      <td>3585.0</td>\n",
       "      <td>6</td>\n",
       "      <td>part-1.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.jstor.org/stable/1808956</td>\n",
       "      <td>Tariffs, Intermediate Goods, and Domestic Prot...</td>\n",
       "      <td>The American Economic Review</td>\n",
       "      <td>1969</td>\n",
       "      <td>10.2307/1808956</td>\n",
       "      <td>article</td>\n",
       "      <td>research-article</td>\n",
       "      <td>jstor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969-06-01</td>\n",
       "      <td>...</td>\n",
       "      <td>Roy J. Ruffin</td>\n",
       "      <td>American Economic Association</td>\n",
       "      <td>eng</td>\n",
       "      <td>261</td>\n",
       "      <td>269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>effective tariff; tariff rate; effective tarif...</td>\n",
       "      <td>4840.0</td>\n",
       "      <td>9</td>\n",
       "      <td>part-1.jsonl.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.jstor.org/stable/2728408</td>\n",
       "      <td>L: Industrial Organization</td>\n",
       "      <td>Journal of Economic Literature</td>\n",
       "      <td>1993</td>\n",
       "      <td>10.2307/2728408</td>\n",
       "      <td>article</td>\n",
       "      <td>misc</td>\n",
       "      <td>jstor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-12-01</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Economic Association</td>\n",
       "      <td>eng</td>\n",
       "      <td>2360</td>\n",
       "      <td>2371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english summary; market; econ societes; amer e...</td>\n",
       "      <td>7775.0</td>\n",
       "      <td>12</td>\n",
       "      <td>part-1.jsonl.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  http://www.jstor.org/stable/44955205   \n",
       "1   http://www.jstor.org/stable/1808822   \n",
       "2   http://www.jstor.org/stable/1924813   \n",
       "3   http://www.jstor.org/stable/1808956   \n",
       "4   http://www.jstor.org/stable/2728408   \n",
       "\n",
       "                                               title  \\\n",
       "0  SUBMISSION OF MANUSCRIPTS TO THE ECONOMETRIC S...   \n",
       "1                                          New Books   \n",
       "2  U.S. Evidence on Linear Feedback from Money Gr...   \n",
       "3  Tariffs, Intermediate Goods, and Domestic Prot...   \n",
       "4                         L: Industrial Organization   \n",
       "\n",
       "                                 isPartOf  publicationYear               doi  \\\n",
       "0                            Econometrica             2018  10.2307/44955205   \n",
       "1            The American Economic Review             1933   10.2307/1808822   \n",
       "2  The Review of Economics and Statistics             1985   10.2307/1924813   \n",
       "3            The American Economic Review             1969   10.2307/1808956   \n",
       "4          Journal of Economic Literature             1993   10.2307/2728408   \n",
       "\n",
       "   docType        docSubType provider  collection datePublished  ...  \\\n",
       "0  article              misc    jstor         NaN    2018-01-01  ...   \n",
       "1  article  research-article    jstor         NaN    1933-03-01  ...   \n",
       "2  article  research-article    jstor         NaN    1985-11-01  ...   \n",
       "3  article  research-article    jstor         NaN    1969-06-01  ...   \n",
       "4  article              misc    jstor         NaN    1993-12-01  ...   \n",
       "\n",
       "                                creator                      publisher  \\\n",
       "0  Jeffrey C. Ely; Donald W. K. Andrews                          Wiley   \n",
       "1                                   NaN  American Economic Association   \n",
       "2                      Mary G. McGarvey                  The MIT Press   \n",
       "3                         Roy J. Ruffin  American Economic Association   \n",
       "4                                   NaN  American Economic Association   \n",
       "\n",
       "  language pageStart pageEnd placeOfPublication  \\\n",
       "0      eng       389     389                NaN   \n",
       "1      eng       139     140                NaN   \n",
       "2      eng       675     680                NaN   \n",
       "3      eng       261     269                NaN   \n",
       "4      eng      2360    2371                NaN   \n",
       "\n",
       "                                           keyphrase wordCount  pageCount  \\\n",
       "0  pdf format; electronic submissions; manuscript...     352.0          1   \n",
       "1  kartelle berlin; heymanns verlag; carl heymann...     117.0          2   \n",
       "2  relative price; feedback; growth shocks; money...    3585.0          6   \n",
       "3  effective tariff; tariff rate; effective tarif...    4840.0          9   \n",
       "4  english summary; market; econ societes; amer e...    7775.0         12   \n",
       "\n",
       "              file  \n",
       "0  part-1.jsonl.gz  \n",
       "1  part-1.jsonl.gz  \n",
       "2  part-1.jsonl.gz  \n",
       "3  part-1.jsonl.gz  \n",
       "4  part-1.jsonl.gz  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inmeta = pd.read_csv('../../metadata/econ-jstor-metadata.csv')\n",
    "inmeta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c184e67b-74dc-478f-8de3-1c3f41f4f0ac",
   "metadata": {},
   "source": [
    "#### fall-back option\n",
    "\n",
    "If there is no metadata file we can iterate through the json provided by JSTOR and extract metadata. Probably not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68b579e4-d040-468a-a9f0-b46aa5fe1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(infile, outfile):\n",
    "    '''\n",
    "    Iterates through a jsonl file where each article is represented as a line.\n",
    "    Extracts metadata and saves it to outfile as a tab-separated-value file.\n",
    "    '''\n",
    "    jauthors = []\n",
    "    jtitles = []\n",
    "    dois = []\n",
    "    jyears = []\n",
    "    jdoctypes = []\n",
    "    jwordcounts = []\n",
    "    journals = []\n",
    "    languages = []\n",
    "\n",
    "    with open(infile, mode = 'r', encoding = 'utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        ctr = 0\n",
    "        for l in lines:\n",
    "            j = json.loads(l)\n",
    "            ctr += 1\n",
    "            if ctr % 500 == 1:\n",
    "                print(ctr)\n",
    "            if 'creator' in j:\n",
    "                jauthors.append(j['creator'])\n",
    "            else:\n",
    "                jauthors.append(\"['anonymous']\")\n",
    "            doctype = j['docType'] + \" | \" + j['docSubType']\n",
    "            jdoctypes.append(doctype)\n",
    "            jwordcounts.append(j['wordCount'])\n",
    "            jyears.append(j['publicationYear'])\n",
    "            jtitles.append(j['title'])\n",
    "            journals.append(j['isPartOf'])\n",
    "            ids = j['identifier']\n",
    "            thedoi = 'no doi'\n",
    "            for anid in ids:\n",
    "                if anid['name'] == 'local_doi':\n",
    "                    thedoi = anid['value']\n",
    "            dois.append(thedoi)\n",
    "            languages.append(j['language'])\n",
    "\n",
    "    themeta = pd.DataFrame({'journal': journals, 'year': jyears, 'authors': jauthors,\n",
    "                           'title': jtitles, 'language': languages,\n",
    "                           'wordcount': jwordcounts, 'doctype': jdoctypes, 'doi': dois})\n",
    "    themeta.to_csv(outfile, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a1fcf-ea87-4dfc-aaac-ebd49d3caaae",
   "metadata": {},
   "source": [
    "#### check document types\n",
    "\n",
    "This was simple in Econ. We just filter out \"misc.\" If there are a lot more in Ecology, we may want to adjust the code to filter out other non-article doctypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59fdf947-0786-4396-8e86-17278d74f2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'book-review', 'misc', 'research-article'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctypes = set(inmeta.docSubType)\n",
    "doctypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c31db-9692-4fb3-8b76-a4e3329316f8",
   "metadata": {},
   "source": [
    "### Functions that evaluate match strength\n",
    "\n",
    "We define functions to compare pairs of titles, lists of authors, and publication year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edff87df-0e29-49f4-afe8-2f62219d4f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Ratio: 0.9795918367346939, Shorter Title Length: 48\n"
     ]
    }
   ],
   "source": [
    "def compare_titles(title1, title2):\n",
    "    \n",
    "    '''We first lowercase both titles using the lower() method for \n",
    "    a case-insensitive comparison.\n",
    "    We check if the lowercased titles are exactly the same. If so, \n",
    "    we return 1.0 and the length of the shorter title.\n",
    "    If the titles aren't exactly the same, we truncate both titles \n",
    "    to a maximum of 50 characters using string slicing. The logic is\n",
    "    that we suspect the trailing characters are optional boilerplate.\n",
    "    We then determine the length of the shorter title (or 50 if either\n",
    "    title was truncated).\n",
    "    Finally, we use SequenceMatcher from the difflib module to \n",
    "    calculate the similarity ratio between the truncated titles, \n",
    "    and return the similarity ratio along with the length of the \n",
    "    shorter title.\n",
    "    '''\n",
    "    \n",
    "    # Lowercase the titles for case-insensitive comparison\n",
    "    title1 = title1.lower()\n",
    "    title2 = title2.lower()\n",
    "    \n",
    "    # Check for exact match when lowercased\n",
    "    if title1 == title2:\n",
    "        return 1.0, min(len(title1), len(title2))\n",
    "    \n",
    "    # Truncate titles to 50 characters if necessary\n",
    "    max_length = 50\n",
    "    title1_truncated = title1[:max_length]\n",
    "    title2_truncated = title2[:max_length]\n",
    "    \n",
    "    # Get the length of the shorter title (or 50 if truncated)\n",
    "    shorter_title_length = min(len(title1_truncated), len(title2_truncated))\n",
    "    \n",
    "    # Calculate similarity ratio using SequenceMatcher\n",
    "    similarity_ratio = SequenceMatcher(None, title1_truncated, title2_truncated).ratio()\n",
    "    \n",
    "    return similarity_ratio, shorter_title_length\n",
    "\n",
    "# Usage:\n",
    "title1 = \"A Long Title That Might Have Additional Subtitle\"\n",
    "title2 = \"A long title that might have additional subtitle (Translated from the French by Pierre Menard)\"\n",
    "similarity_ratio, shorter_title_length = compare_titles(title1, title2)\n",
    "print(f'Similarity Ratio: {similarity_ratio}, Shorter Title Length: {shorter_title_length}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de73172-b976-45cf-a998-84d799b56d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def compare_author_lists(author_list1, author_list2):\n",
    "    \n",
    "    '''\n",
    "    Our strategy uses only last names, because middle and first names\n",
    "    may be omitted or reduced to initials.\n",
    "    \n",
    "    We extract the last names from author_list1 and author_list2 by\n",
    "    splitting each name string on spaces and taking the last element.\n",
    "    We use a set comprehension create sets of unique last names, then\n",
    "    iterate through the last names in last_names_list1 and check if each\n",
    "    last name exists in last_names_list2, incrementing matching_last_names_count\n",
    "    for each match.\n",
    "    \n",
    "    Finally, we calculate the fraction of matching last names by \n",
    "    dividing matching_last_names_count by the total number of unique last \n",
    "    names in last_names_list1, and return this fraction.\n",
    "    '''\n",
    "    \n",
    "    # If the first list is empty, return None\n",
    "    if not author_list1:\n",
    "        return None\n",
    "    \n",
    "    # Extract last names from the first list\n",
    "    last_names_list1 = set()\n",
    "    for name in author_list1:\n",
    "        if len(name) > 0:\n",
    "            last_names_list1.add(name.split()[-1].lower())\n",
    "    \n",
    "    last_names_list2 = set()\n",
    "    for author in author_list2:\n",
    "        if 'name' in author and len(author['name']) > 0:\n",
    "            last_names_list2.add(author['name'].split()[-1].lower())\n",
    "    \n",
    "    # Find the count of matching last names\n",
    "    matching_last_names_count = sum(1 for last_name in last_names_list1 if last_name in last_names_list2)\n",
    "    \n",
    "    # Calculate and return the fraction of matching last names\n",
    "    matching_fraction = matching_last_names_count / len(last_names_list1)\n",
    "    return matching_fraction\n",
    "\n",
    "# Usage:\n",
    "author_list1 = ['Michael D. Bauer', 'Glenn D. Rudebusch']\n",
    "author_list2 = [{'authorId': '145421946', 'name': 'M. BAUER'}, {'authorId': '65729671', 'name': 'Glenn D. Rudebusch'}]\n",
    "\n",
    "matching_fraction = compare_author_lists(author_list1, author_list2)\n",
    "print(matching_fraction)  # Output: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf571de-7826-413b-9306-70479a09664f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "def compare_dates(date1, date2):\n",
    "    '''\n",
    "    We return the absolute difference between two dates, or 7\n",
    "    if they are difficult to compare.\n",
    "    \n",
    "    The logic is that 7 years apart is not a close match but not\n",
    "    impossible; it's a neutral result.\n",
    "    '''\n",
    "    \n",
    "    if not date1 or not date2:\n",
    "        return 7 \n",
    "    elif len(date2) < 4:\n",
    "        return 7\n",
    "    else:\n",
    "        try:\n",
    "            date2 = int(date2[0:4])\n",
    "        except:\n",
    "            return 7\n",
    "        \n",
    "        return abs(date1 - date2)\n",
    "\n",
    "print(compare_dates(1989, '197o-8-17'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab81fed9-b9f2-4bf2-bab8-b3f50b69d4a2",
   "metadata": {},
   "source": [
    "#### Final evaluation of match\n",
    "\n",
    "this function pulls together all the functions defined above to make an overall evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e5138e-aedd-48af-ba01-866653c44149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_strength(title1, title2, author_list1, author_list2,\n",
    "                   date1, date2):\n",
    "    ''' Makes three comparisons and returns an overall metric of\n",
    "    match strength.\n",
    "    \n",
    "    Our metric is mostly dependent on the title (0-1.0), but author matches\n",
    "    can add up to 0.1, and date distance can subtract up to 0.1, or add 0.02.\n",
    "    \n",
    "    The final result should be 1.0 or greater to be trusted.\n",
    "    '''\n",
    "    \n",
    "    titlematch, titlelen = compare_titles(title1, title2)\n",
    "    \n",
    "    if titlelen < 10:  \n",
    "        titlematch = titlematch * (titlelen / 10)\n",
    "    # short titles aren't as informative\n",
    "    \n",
    "    authormatch = compare_author_lists(author_list1, author_list2)\n",
    "    # datedistance = compare_dates(date1, date2)\n",
    "    \n",
    "    if date1 is None or date2 is None:\n",
    "        datedistance = 7\n",
    "    else:\n",
    "        datedistance = abs(date1 - date2)\n",
    "    \n",
    "    if not authormatch:\n",
    "        authormatch = 0\n",
    "    \n",
    "    authorbonus = (0.1 * authormatch)\n",
    "    if datedistance == 0:\n",
    "        datepenalty = -0.02 # an exact match is a negative penalty aka bonus\n",
    "    elif datedistance < 4:\n",
    "        datepenalty = 0\n",
    "    elif datedistance < 7:\n",
    "        datepenalty = 0.04\n",
    "    elif datedistance < 12:\n",
    "        datepenalty = 0.07\n",
    "    else:\n",
    "        datepenalty = 0.1\n",
    "        \n",
    "    totalmatch = titlematch + authorbonus - datepenalty\n",
    "    return totalmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4729d4e-1617-481f-9a8d-2c1d4d4d4079",
   "metadata": {},
   "source": [
    "### Functions that do the searching\n",
    "\n",
    "First a utility that turns a title into a string that can be used in the API url.\n",
    "\n",
    "Note: this is probably not necessary. I wrote it before I started passing the query in \"params\" to the request library. Now, I suspect the requests library does what is needed. But I haven't tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e4ba69-b8a1-4454-852d-71f853ab0355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the end of o clock shadow shaving depilation removal and gilette other strategies\n"
     ]
    }
   ],
   "source": [
    "def title_to_url(title):\n",
    "    '''\n",
    "    Slightly deprecated.\n",
    "    '''\n",
    "    # handle possessives\n",
    "    title = title.replace(\"'s \", \" \")\n",
    "    # Replace hyphens, slashes, and apostrophes with spaces\n",
    "    title = re.sub(r'[-/\\'’]', ' ', title)\n",
    "    # Remove non-alphabetic characters (excluding spaces)\n",
    "    title = re.sub(r'[^a-zA-Z\\s]', '', title)\n",
    "    # Convert to lower case\n",
    "    title = title.lower()\n",
    "    # Replace double spaces\n",
    "    url_string = re.sub('  ', ' ', title)\n",
    "    return url_string\n",
    "\n",
    "# Usage:\n",
    "title = \"The End of 5-O'Clock-Shadow? Shaving, Depilation/Removal, and Gilette's Other Strategies.\"\n",
    "url_string = title_to_url(title)\n",
    "print(url_string)  # Output: the+end+of+o+clock+shadow+shaving+depilation+removal+and+gilette+other+strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4721ec-41f8-4c46-b704-83bf95fc3b61",
   "metadata": {},
   "source": [
    "### Iterate through papers to find the best match\n",
    "\n",
    "Given metadata for an article, derived from JSTOR, and a list of papers from S2, this finds the best match in the list of papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6376a6c-8b24-4188-93c0-763ab0a5fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_papers(title, authors, journal, year, papers, journalpenalty):\n",
    "    '''\n",
    "    Title, author, year, and journal are derived from JSTOR metadata.\n",
    "    \n",
    "    Papers is a list of papers we have received from S2.\n",
    "    \n",
    "    We iterate through papers and return the best match.\n",
    "    '''\n",
    "    bestmatch = -1\n",
    "    bestmatchstrength = 0\n",
    "\n",
    "    for idx, paper in enumerate(papers):\n",
    "        if 'title' in paper:\n",
    "            foundtitle = paper['title']\n",
    "        else:\n",
    "            foundtitle = ''\n",
    "        if 'authors' in paper:\n",
    "            foundauthors = paper['authors']\n",
    "        else:\n",
    "            foundauthors = []\n",
    "        if 'year' in paper and not paper['year'] is None:\n",
    "            founddate = paper['year']\n",
    "        else:\n",
    "            founddate = None\n",
    "\n",
    "        if 'journal' in paper and not paper['journal'] is None:\n",
    "            if 'name' in paper['journal']:\n",
    "                foundjournal = paper['journal']['name']\n",
    "            else:\n",
    "                foundjournal = ''\n",
    "        else:\n",
    "            foundjournal = ''\n",
    "\n",
    "        totalmatch = match_strength(title, foundtitle, authors,\n",
    "                                    foundauthors, year, founddate)\n",
    "\n",
    "        if journal.lower() not in foundjournal.lower():\n",
    "            totalmatch = totalmatch - journalpenalty\n",
    "\n",
    "        if totalmatch > 0.7 and totalmatch > bestmatchstrength:\n",
    "            bestmatchstrength = totalmatch\n",
    "            bestmatch = idx\n",
    "    \n",
    "    return papers[bestmatch], bestmatchstrength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7adcbd-29e0-4851-bd1b-f7856ee26cb0",
   "metadata": {},
   "source": [
    "### Combine DOI search and title search\n",
    "\n",
    "This function tries for an exact match on the DOI, and then also runs a title search. It returns the results of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4429ca9c-75c6-4371-a4ee-dbad78492297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(DOI, title, authors, journal, year = None, journalpenalty = 0.05):\n",
    "    '''\n",
    "    This function finds the closest match for an article with a given\n",
    "    title, list of authors, journal of publication, and publication year.\n",
    "    \n",
    "    There's a default penalty for appearing in the wrong journal, but\n",
    "    it allows the user to override that penalty (some journals republish\n",
    "    articles from others and it's not surprising to have the wrong journal\n",
    "    title in those cases).\n",
    "    \n",
    "    We return the best paper, as a json object, and the match strength.\n",
    "    \n",
    "    If there's an exact DOI match we also return that.\n",
    "    \n",
    "    If either attempt fails, we return None for that part.\n",
    "    '''\n",
    "    \n",
    "    url=\"https://api.semanticscholar.org/graph/v1/paper/DOI:\"+DOI\n",
    "    url = url + \"?fields=title,year,authors,citationCount,externalIds,citations,journal\"\n",
    "    \n",
    "    response = requests.get(url, headers={'X-API-KEY': apikey})\n",
    "    \n",
    "    foundDOI = False\n",
    "    if response.status_code == 200:\n",
    "        jsonobj = response.json()\n",
    "        papers = [jsonobj]\n",
    "        foundDOI = True\n",
    "        doimatch, doimatchstrength = evaluate_papers(title, authors, journal, year, papers, journalpenalty)\n",
    "\n",
    "    query = title_to_url(title)\n",
    "    \n",
    "    response = requests.get('https://api.semanticscholar.org/graph/v1/paper/search',\n",
    "                           headers={'X-API-KEY': apikey},\n",
    "                           params={'query': query, 'limit': 15, \n",
    "                                   'fields': 'title,authors,year,citationCount,externalIds,journal,citations'})\n",
    "    \n",
    "    successfulsearch = False\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        jsonobj = response.json()\n",
    "        if 'data' in jsonobj:\n",
    "            papers = jsonobj['data']\n",
    "            searchmatch, searchmatchstrength = evaluate_papers(title, authors, journal, year, papers, journalpenalty)\n",
    "            successfulsearch = True\n",
    "                  \n",
    "    if not foundDOI and not successfulsearch:\n",
    "        return None, -1, None, -1, 'neither'\n",
    "    elif foundDOI and not successfulsearch:\n",
    "        return doimatch, doimatchstrength, None, -1, 'DOI'\n",
    "    elif not foundDOI and successfulsearch:\n",
    "        return None, -1, searchmatch, searchmatchstrength, 'search'\n",
    "    else:\n",
    "        if searchmatchstrength > doimatchstrength:\n",
    "            thebetter = 'search'\n",
    "        else:\n",
    "            thebetter = 'DOI'\n",
    "            \n",
    "        return doimatch, doimatchstrength, searchmatch, searchmatchstrength, thebetter\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc47927-996c-4dce-9161-16bf1bf59c03",
   "metadata": {},
   "source": [
    "### Utility function to enrich JSTOR metadata \"row\"\n",
    "\n",
    "As we iterate through the JSTOR metadata file we add new fields to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "705cac3c-904f-4ce3-98af-86c5c7d31f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_paper(row, paper):\n",
    "    \n",
    "    new_row = row.copy()\n",
    "    \n",
    "    new_row['paperId'] = paper['paperId']\n",
    "    \n",
    "    if 'citationCount' in paper:\n",
    "        new_row['citationCount'] = paper['citationCount']\n",
    "    else:\n",
    "        new_row['citationCount'] = 0\n",
    "                \n",
    "    if 'title' in paper:\n",
    "        new_row['foundTitle'] = paper['title']\n",
    "    else:\n",
    "        new_row['foundTitle'] = 'NA'\n",
    "                \n",
    "    if 'year' in paper:\n",
    "        new_row['foundYear'] = paper['year']\n",
    "    else:\n",
    "        new_row['foundYear'] = 0\n",
    "                \n",
    "    if 'authors' in paper:\n",
    "        new_row['foundAuthors'] = ' | '.join([x['name'] for x in paper['authors']])\n",
    "    else:\n",
    "        new_row['foundAuthors'] = 'NA'\n",
    "    \n",
    "    if 'citations' in paper and paper['citationCount'] < 900:\n",
    "        citation_list = []\n",
    "        for x in paper['citations']:\n",
    "            if 'paperId' in x and x['paperId'] is not None:\n",
    "                citation_list.append(x['paperId'])\n",
    "            \n",
    "        new_row['citations'] = ' | '.join(citation_list)\n",
    "    elif paper['citationCount'] >= 900:\n",
    "        citation_list, got_contexts = get_all_citations(paper['paperId'], paper['citationCount'])\n",
    "        new_row['citations'] = ' | '.join(citation_list)\n",
    "    else:\n",
    "        new_row['citations'] = 'NA'\n",
    "        citation_list = []\n",
    "    \n",
    "    foundCitations = len(citation_list)\n",
    "    if 'citationCount' in paper:\n",
    "        citationCount = paper['citationCount']\n",
    "    else:\n",
    "        citationCount = 0\n",
    "    \n",
    "    if (citationCount - foundCitations) > (citationCount / 3):\n",
    "        print('SUSPICIOUS CITATON GAP: ', citationCount, foundCitations)\n",
    "        \n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e387465f-d11b-49ae-a63f-543d7d642433",
   "metadata": {},
   "source": [
    "### Get citations if more than 1000\n",
    "\n",
    "If there are more than 1000 citations we may need to iterate through multiple \"pages\" of citations and aggregate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3fc9b700-8506-4ce2-84c7-4c59ccd8d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_citations(paperId, citationCount):\n",
    "    \n",
    "    url = 'https://api.semanticscholar.org/graph/v1/paper/' + paperId + '/citations'\n",
    "    citations = []\n",
    "    got_contexts = False\n",
    "    for offset in range(0, citationCount, 1000):  \n",
    "        response = requests.get(url, \n",
    "                                headers={'X-API-KEY': apikey},\n",
    "                               params={'offset': offset, 'limit': 1000, \n",
    "                                       'fields': 'contexts,year'})\n",
    "        if response.status_code == 200:\n",
    "            jsonobj = response.json()\n",
    "            data = jsonobj['data']\n",
    "            for cite in data:\n",
    "                if 'contexts' in cite:\n",
    "                    if len(cite['contexts']) > 0:\n",
    "                        got_contexts = True\n",
    "                if 'citingPaper' in cite:\n",
    "                    if 'paperId' in cite['citingPaper']:\n",
    "                        if cite['citingPaper']['paperId'] is not None:\n",
    "                            citations.append(cite['citingPaper']['paperId'])\n",
    "    \n",
    "    print('Paper with ', len(citations), 'citations.')\n",
    "    \n",
    "    return citations, got_contexts \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac489620-280f-4471-9e31-cf21bd12b012",
   "metadata": {},
   "source": [
    "## Match A Segment\n",
    "\n",
    "This is the main show: the function you need to call to match your metadata with S2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3fa8909-5c2a-4b4e-aa46-7a620ef6e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_a_segment(metadata, startrow, endrow, outfile_prefix):\n",
    "    \n",
    "    '''\n",
    "    Iterates through metadata from startrow to endrow, and saves\n",
    "    the results to two outfiles: a new metadata file containing\n",
    "    rows where matches were found, and a paper file containing the\n",
    "    jsons for found papers.\n",
    "    \n",
    "    The outfiles are both named using a consistent \n",
    "    pattern so that all the outfiles can be concatenated automatically\n",
    "    when you're done.\n",
    "    \n",
    "    So e.g. if you say\n",
    "    match_a_segment(inmeta, 0, 5000, 'econ')\n",
    "    \n",
    "    the results will be saved to \n",
    "    econ-meta-0-5000.tsv and econ-papers-0-5000.jsonl,\n",
    "    \n",
    "    overwriting any existing files with those names.\n",
    "    '''\n",
    "    \n",
    "    # create outfile name\n",
    "    outmetafile = outfile_prefix + '-meta-' + str(startrow) + '-' + str(endrow) + '.tsv'\n",
    "    outpaperfile = outfile_prefix + '-papers-' + str(startrow) + '-' + str(endrow) + '.jsonl'\n",
    "    \n",
    "    assert endrow > startrow\n",
    "    \n",
    "    metalength = metadata.shape[0]\n",
    "    if endrow > metalength:\n",
    "        endrow = metalength\n",
    "    \n",
    "    itermeta = metadata.iloc[startrow: endrow, : ]\n",
    "    \n",
    "    titledist = Counter(metadata.title)\n",
    "    common_titles = titledist.most_common(120)\n",
    "    forbidden_titles = set([x[0] for x in common_titles])\n",
    "    \n",
    "    print('TITLES TOO COMMON TO SEARCH ON:')\n",
    "    for title, freq in common_titles:\n",
    "        print(title, freq)\n",
    "    print()\n",
    "    \n",
    "    all_new_rows = []\n",
    "    all_papers = []\n",
    "    \n",
    "    for idx, row in itermeta.iterrows():\n",
    "        \n",
    "        if idx % 100 == 1:\n",
    "            print('INDEX: ', idx)\n",
    "            print()\n",
    "        \n",
    "        if row.docSubType == 'misc':\n",
    "            continue\n",
    "        \n",
    "        # we don't trust *search* matches on Forbidden Titles\n",
    "        # they are too common to be meaningful\n",
    "        \n",
    "        if row.title in forbidden_titles:\n",
    "            continue\n",
    "        \n",
    "        creators = []\n",
    "        if not pd.isnull(row['creator']) and not pd.isna(row['creator']):\n",
    "            creators = row['creator'].split(';')\n",
    "            \n",
    "        doimatch, doimatchstrength, searchmatch, searchmatchstrength, thebetter = search_papers(row['doi'], row['title'], \n",
    "                                             creators, row['isPartOf'], row['publicationYear'])\n",
    "        \n",
    "        # if we found an exact match to the DOI we should be more confident\n",
    "        # about that match, and the search match as well (if it has the same\n",
    "        # paper id)\n",
    "        \n",
    "        if doimatchstrength > 0.7:\n",
    "            doimatchstrength += 0.05 # DOI matches are inherently stronger\n",
    "            if searchmatchstrength > 0.7:\n",
    "                doipaper = doimatch['paperId']\n",
    "                searchpaper = searchmatch['paperId']\n",
    "                if doipaper == searchpaper:\n",
    "                    doimatchstrength += 0.05\n",
    "                    searchmatchstrength += 0.05\n",
    "                else:\n",
    "                    searchmatchstrength -= 0.15\n",
    "                    # we favor DOI in case of disagreement\n",
    "        \n",
    "        if doimatchstrength < 0.7 and searchmatchstrength < 0.7:\n",
    "            continue    # initial threshold of 0.7 for matches\n",
    "        elif doimatchstrength > searchmatchstrength:\n",
    "            new_row = extract_metadata_from_paper(row, doimatch)\n",
    "            new_row['paperSource'] = 'DOI'\n",
    "            all_papers.append(doimatch)\n",
    "        else:\n",
    "            new_row = extract_metadata_from_paper(row, searchmatch)\n",
    "            new_row['paperSource'] = 'search'\n",
    "            all_papers.append(searchmatch)\n",
    "        \n",
    "        new_row['doiMatch'] = doimatchstrength\n",
    "        new_row['searchMatch'] = searchmatchstrength\n",
    "        \n",
    "        all_new_rows.append(new_row)\n",
    "            \n",
    "    new_df = pd.DataFrame(all_new_rows)\n",
    "    new_df.reset_index(drop = False, inplace = True) # keep old indices\n",
    "    \n",
    "    new_df.to_csv(outmetafile, sep = '\\t', index = False) \n",
    "    \n",
    "    with open(outpaperfile, mode = 'w', encoding = 'utf-8') as f:\n",
    "        for paper in all_papers:\n",
    "            outstring = json.dumps(paper)\n",
    "            f.write(outstring + '\\n')\n",
    "    \n",
    "    print('Write completed sucessfully')\n",
    "    print(len(all_papers), ' papers written.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01024fe2-71c8-4e93-99dd-c644231eba1c",
   "metadata": {},
   "source": [
    "### illustrative example of a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "053d55ac-231f-4ad1-9e8b-a50faccc1760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLES TOO COMMON TO SEARCH ON:\n",
      "Review Article 21643\n",
      "Front Matter 3087\n",
      "Back Matter 2727\n",
      "New Books 2012\n",
      "Volume Information 796\n",
      "Discussion 548\n",
      "Books Received 392\n",
      "400: International Economics 264\n",
      "900: Welfare Programs; Consumer Economics; Urban and Regional Economics 262\n",
      "100: Economic Growth; Development; Planning; Fluctuations 261\n",
      "000: General Economics; Theory; History; Systems 261\n",
      "500: Administration; Business Finance; Marketing; Accounting 260\n",
      "800: Manpower; Labor; Population 243\n",
      "600: Industrial Organization; Technological Change; Industry Studies 233\n",
      "300: Domestic Monetary and Fiscal Theory and Institutions 218\n",
      "Periodicals 205\n",
      "700: Agriculture; Natural Resources 201\n",
      "New Journals 197\n",
      "200: Quantitative Economic Methods and Data 191\n",
      "Related Disciplines 145\n",
      "Recent Publications 141\n",
      "L: Industrial Organization 134\n",
      "N: Economic History 134\n",
      "C: Mathematical and Quantitative Methods 134\n",
      "K: Law and Economics 134\n",
      "G: Financial Economics 134\n",
      "F: International Economics 134\n",
      "A: General Economics and Teaching 134\n",
      "H: Public Economics 134\n",
      "D: Microeconomics 134\n",
      "J: Labor and Demographic Economics 133\n",
      "P: Economic Systems 133\n",
      "E: Macroeconomics and Monetary Economics 133\n",
      "I: Health, Education, and Welfare 133\n",
      "Classification System for Books 129\n",
      "Accepted Manuscripts 125\n",
      "Contents of Current Periodicals 124\n",
      "O: Economic Development, Technological Change, and Growth 123\n",
      "Z: Other Special Topics 121\n",
      "R: Urban, Rural, and Regional Economics 114\n",
      "Miscellanea 114\n",
      "Washington Notes 110\n",
      "Titles of New Books 106\n",
      "Q: Agricultural and Natural Resource Economics 90\n",
      "Documents, Reports, and Legislation 89\n",
      "Classification System for Articles and Abstracts 88\n",
      "Publications Received 83\n",
      "JEL Classification System 78\n",
      "B: Methodology and History of Economic Thought 76\n",
      "200: Economic Statistics 71\n",
      "Index of Authors of Articles in the Subject Index 69\n",
      "Recent Publications Upon Economics 63\n",
      "700: Agriculture: Natural Resources 61\n",
      "Announcements 56\n",
      "ANNOUNCEMENTS 54\n",
      "New Publications 50\n",
      "Submission of Manuscripts to Econometrica 49\n",
      "M: Business Administration and Business Economics; Marketing; Accounting 44\n",
      "300: Monetary and Fiscal Theory and Institutions 44\n",
      "FORTHCOMING PAPERS 42\n",
      "Q: Agricultural and Natural Resource Economics • Environmental and Ecological Economics 37\n",
      "Y: Miscellaneous Categories 37\n",
      "MISCELLANEA 36\n",
      "Classification System for Journal Articles 35\n",
      "M: Business Administration and Business Economics • Marketing • Accounting 33\n",
      "B: Schools of Economic Thought and Methodology 32\n",
      "Introduction 31\n",
      "News Notes 29\n",
      "[Notes] 27\n",
      "B: History of Economic Thought, Methodology, and Heterodox Approaches 26\n",
      "600: Industrial Organization; Technical Change; Industry Studies 24\n",
      "Publications of the American Economic Association 24\n",
      "Fellows of the Econometric Society 24\n",
      "E Macroeconomics and Monetary Economics 23\n",
      "Recent Publications upon Economics 23\n",
      "G Financial Economics 22\n",
      "L Industrial Organization 22\n",
      "D Microeconomics 22\n",
      "P Economic Systems 22\n",
      "C Mathematical and Quantitative Methods 22\n",
      "N Economic History 22\n",
      "A General Economics and Teaching 22\n",
      "K Law and Economics 22\n",
      "H Public Economics 22\n",
      "J Labor and Demographic Economics 22\n",
      "B History of Economic Thought, Methodology, and Heterodox Approaches 22\n",
      "I Health, Education, and Welfare 22\n",
      "F International Economics 22\n",
      "Z Other Special Topics 21\n",
      "List of Members of the Econometric Society 21\n",
      "Y Miscellaneous Categories 21\n",
      "Foreword 20\n",
      "Index of Authors of Selected Abstracts 20\n",
      "M: Business Administration and Business Economics, Marketing, Accounting 19\n",
      "800: Manpower; Labor Population 19\n",
      "Unpublished Research Memoranda 19\n",
      "Index of Authors of Articles in The Subject Index 19\n",
      "Editorial Collaborators 18\n",
      "Independent Auditors' Report 18\n",
      "Notices 18\n",
      "R Urban, Rural, Regional, Real Estate, and Transportation Economics 18\n",
      "Selected Statistical Data 17\n",
      "Documents, Reports and Legislation 16\n",
      "R: Urban, Rural, Regional, Real Estate, and Transportation Economics 15\n",
      "French Economic Conditions 15\n",
      "O Economic Development, Innovation, Technological Change, and Growth 15\n",
      "General Economic Conditions in the United States 15\n",
      "Journal of Political Economy 14\n",
      "The Quarterly Journal of Economics 14\n",
      "The United States: Index of General Business 14\n",
      "Editors' Introduction 14\n",
      "British Economic Conditions 14\n",
      "Introductory Remarks 14\n",
      "SUBMISSION OF MANUSCRIPTS TO THE ECONOMETRIC SOCIETY MONOGRAPH SERIES 13\n",
      "Appendix: Corrected Items of Various Series of Business Statistics 13\n",
      "Unpublished Memoranda 12\n",
      "M Business Administration and Business Economics • Marketing • Accounting • Personnel Economics 12\n",
      "Q Agricultural and Natural Resource Economics • Environmental and Ecological Economics 12\n",
      "JOURNAL OF POLITICAL ECONOMY 11\n",
      "American Finance Association Business Proceedings 11\n",
      "\n",
      "INDEX:  2001\n",
      "\n",
      "Paper with  1003 citations.\n",
      "INDEX:  2101\n",
      "\n",
      "Paper with  2477 citations.\n",
      "Paper with  1141 citations.\n",
      "Paper with  1597 citations.\n",
      "INDEX:  2201\n",
      "\n",
      "INDEX:  2301\n",
      "\n",
      "Paper with  1104 citations.\n",
      "INDEX:  2401\n",
      "\n",
      "Paper with  3220 citations.\n",
      "Paper with  1265 citations.\n",
      "Paper with  1440 citations.\n",
      "INDEX:  2501\n",
      "\n",
      "Paper with  1135 citations.\n",
      "Paper with  1569 citations.\n",
      "Paper with  898 citations.\n",
      "INDEX:  2601\n",
      "\n",
      "Paper with  1025 citations.\n",
      "Paper with  1877 citations.\n",
      "Paper with  1166 citations.\n",
      "Paper with  917 citations.\n",
      "Paper with  1569 citations.\n",
      "INDEX:  2701\n",
      "\n",
      "Paper with  1407 citations.\n",
      "INDEX:  2801\n",
      "\n",
      "Paper with  1335 citations.\n",
      "Paper with  981 citations.\n",
      "Paper with  1549 citations.\n",
      "INDEX:  2901\n",
      "\n",
      "Paper with  8999 citations.\n",
      "SUSPICIOUS CITATON GAP:  18140 8999\n",
      "Paper with  949 citations.\n",
      "Paper with  5864 citations.\n",
      "Write completed sucessfully\n",
      "501  papers written.\n"
     ]
    }
   ],
   "source": [
    "match_a_segment(inmeta, 2000, 3000, 'econ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9dc9e-f481-4983-8efe-0c7091312446",
   "metadata": {},
   "source": [
    "### Concatenate the output\n",
    "\n",
    "This function asks for a prefix code like \"econ\" and then finds relevant output files in the local directory. It checks to make sure they're consecutive, and if so, concatenates them.\n",
    "\n",
    "Consecutive, here, means that the startrow of each file is the endrow of the last file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aae5df74-5940-44d9-915c-95711a0362c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_consecutive(listoffiles):\n",
    "    \n",
    "    '''\n",
    "    We accept a list of files in the format\n",
    "    econ-meta-0-1000.tsv or\n",
    "    econ-papers-2000-3000.jsonl\n",
    "    \n",
    "    and return a boolean (whether consecutive)\n",
    "    as well as an ordered list of filenames\n",
    "    '''\n",
    "    \n",
    "    tuplelist = []\n",
    "    for afile in listoffiles:\n",
    "        parts = afile.split('-')\n",
    "        startrow = int(parts[2])\n",
    "        tuplelist.append((startrow, afile))\n",
    "        \n",
    "    tuplelist.sort()\n",
    "    \n",
    "    lastend = 0\n",
    "    consecutive = True\n",
    "    for startrow, afile in tuplelist:\n",
    "        if startrow != lastend:\n",
    "            consecutive = False\n",
    "        parts = afile.split('-')\n",
    "        lastend = int(parts[3].replace('.tsv', '').replace('.jsonl', ''))\n",
    "    \n",
    "    return consecutive, [x[1] for x in tuplelist]\n",
    "            \n",
    "\n",
    "def concat_output(prefix):\n",
    "    metafiles = glob.glob(prefix + '-meta-*.tsv')\n",
    "    paperfiles = glob.glob(prefix + '-papers-*.jsonl')\n",
    "    \n",
    "    consecutive, orderedmeta = are_consecutive(metafiles)\n",
    "    \n",
    "    if not consecutive:\n",
    "        print('Metafiles are not consecutive.')\n",
    "        return 'failed'\n",
    "    else:\n",
    "        print('Concatenating metadata:')\n",
    "    \n",
    "    dataframes = []\n",
    "    for afile in orderedmeta:\n",
    "        df = pd.read_csv(afile, sep = '\\t')\n",
    "        dataframes.append(df)\n",
    "        print(afile)\n",
    "    \n",
    "    fullmeta = pd.concat(dataframes)\n",
    "    print()\n",
    "    \n",
    "    consecutive, orderedpapers = are_consecutive(paperfiles)\n",
    "    \n",
    "    if not consecutive:\n",
    "        print('Papers are not consecutive.')\n",
    "        return 'failed'\n",
    "    else:\n",
    "        print('Concatenating papers:') \n",
    "        \n",
    "    paperlines = []\n",
    "    \n",
    "    for afile in orderedpapers:\n",
    "        print(afile)\n",
    "        with open(afile, encoding = 'utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            paperlines.extend(lines)\n",
    "    print()\n",
    "    \n",
    "    outmetaname = 'all-' + prefix + '-S2meta.tsv'\n",
    "    fullmeta.to_csv(outmetaname, sep = '\\t', index = False)\n",
    "    \n",
    "    outpapername = 'all-' + prefix + '-S2papers.tsv'\n",
    "    with open(outpapername, mode = 'w', encoding = 'utf-8') as f:\n",
    "        for line in paperlines:\n",
    "            f.write(line + '\\n')\n",
    "    \n",
    "    print('Done.')\n",
    "    return 'success'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87b8c8fb-b42d-4502-9ae4-7a3fb01c187d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating metadata:\n",
      "econ-meta-0-1000.tsv\n",
      "econ-meta-1000-2000.tsv\n",
      "econ-meta-2000-3000.tsv\n",
      "\n",
      "Concatenating papers:\n",
      "econ-papers-0-1000.jsonl\n",
      "econ-papers-1000-2000.jsonl\n",
      "econ-papers-2000-3000.jsonl\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_output('econ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75618b-565e-45e9-b192-35119eef0211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
