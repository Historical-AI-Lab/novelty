@inproceedings{danescu-niculescu-mizilNoCountryOld2013a,
  title = {No Country for Old Members: User Lifecycle and Linguistic Change in Online Communities},
  shorttitle = {No Country for Old Members},
  booktitle = {Proceedings of the 22nd International Conference on {{World Wide Web}}},
  author = {{Danescu-Niculescu-Mizil}, Cristian and West, Robert and Jurafsky, Dan and Leskovec, Jure and Potts, Christopher},
  year = {2013},
  month = may,
  pages = {307--318},
  publisher = {{ACM}},
  address = {{Rio de Janeiro Brazil}},
  doi = {10.1145/2488388.2488416},
  urldate = {2023-08-25},
  isbn = {978-1-4503-2035-1},
  langid = {english},
  file = {/Users/mstudio/Zotero/storage/PRFQ57A6/Danescu-Niculescu-Mizil et al. - 2013 - No country for old members user lifecycle and lin.pdf}
}

@article{ghosalNoveltyDetectionPerspective2022,
  title = {Novelty {{Detection}}: {{A Perspective}} from {{Natural Language Processing}}},
  shorttitle = {Novelty {{Detection}}},
  author = {Ghosal, Tirthankar and Saikh, Tanik and Biswas, Tameesh and Ekbal, Asif and Bhattacharyya, Pushpak},
  year = {2022},
  month = apr,
  journal = {Computational Linguistics},
  volume = {48},
  number = {1},
  pages = {77--117},
  issn = {0891-2017},
  doi = {10.1162/coli_a_00429},
  urldate = {2023-08-25},
  abstract = {The quest for new information is an inborn human trait and has always been quintessential for human survival and progress. Novelty drives curiosity, which in turn drives innovation. In Natural Language Processing (NLP), Novelty Detection refers to finding text that has some new information to offer with respect to whatever is earlier seen or known. With the exponential growth of information all across the Web, there is an accompanying menace of redundancy. A considerable portion of the Web contents are duplicates, and we need efficient mechanisms to retain new information and filter out redundant information. However, detecting redundancy at the semantic level and identifying novel text is not straightforward because the text may have less lexical overlap yet convey the same information. On top of that, non-novel/redundant information in a document may have assimilated from multiple source documents, not just one. The problem surmounts when the subject of the discourse is documents, and numerous prior documents need to be processed to ascertain the novelty/non-novelty of the current one in concern. In this work, we build upon our earlier investigations for document-level novelty detection and present a comprehensive account of our efforts toward the problem. We explore the role of pre-trained Textual Entailment (TE) models to deal with multiple source contexts and present the outcome of our current investigations. We argue that a multipremise entailment task is one close approximation toward identifying semantic-level non-novelty. Our recent approach either performs comparably or achieves significant improvement over the latest reported results on several datasets and across several related tasks (paraphrasing, plagiarism, rewrite). We critically analyze our performance with respect to the existing state of the art and show the superiority and promise of our approach for future investigations. We also present our enhanced dataset TAP-DLND 2.0 and several baselines to the community for further research on document-level novelty detection.},
  file = {/Users/mstudio/Zotero/storage/XYLZUJ7T/Ghosal et al. - 2022 - Novelty Detection A Perspective from Natural Lang.pdf}
}

@misc{sobchukComputationalThematicsComparing2023,
  title = {Computational Thematics: {{Comparing}} Algorithms for Clustering the Genres of Literary Fiction},
  shorttitle = {Computational Thematics},
  author = {Sobchuk, Oleg and {\v S}e{\c l}a, Artjoms},
  year = {2023},
  month = may,
  number = {arXiv:2305.11251},
  eprint = {2305.11251},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.11251},
  urldate = {2023-08-25},
  abstract = {What are the best methods of capturing thematic similarity between literary texts? Knowing the answer to this question would be useful for automatic clustering of book genres, or any other thematic grouping. This paper compares a variety of algorithms for unsupervised learning of thematic similarities between texts, which we call "computational thematics". These algorithms belong to three steps of analysis: text preprocessing, extraction of text features, and measuring distances between the lists of features. Each of these steps includes a variety of options. We test all the possible combinations of these options: every combination of algorithms is given a task to cluster a corpus of books belonging to four pre-tagged genres of fiction. This clustering is then validated against the "ground truth" genre labels. Such comparison of algorithms allows us to learn the best and the worst combinations for computational thematic analysis. To illustrate the sharp difference between the best and the worst methods, we then cluster 5000 random novels from the HathiTrust corpus of fiction.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/mstudio/Zotero/storage/XYRW7TNH/Sobchuk and Šeļa - 2023 - Computational thematics Comparing algorithms for .pdf;/Users/mstudio/Zotero/storage/HM2Z65A7/2305.html}
}

@article{vicinanzaDeeplearningModelPrescient2023,
  title = {A Deep-Learning Model of Prescient Ideas Demonstrates That They Emerge from the Periphery},
  author = {Vicinanza, Paul and Goldberg, Amir and Srivastava, Sameer B},
  year = {2023},
  month = jan,
  journal = {PNAS Nexus},
  volume = {2},
  number = {1},
  pages = {pgac275},
  issn = {2752-6542},
  doi = {10.1093/pnasnexus/pgac275},
  urldate = {2023-08-25},
  abstract = {Where do prescient ideas\textemdash those that initially challenge conventional assumptions but later achieve widespread acceptance\textemdash come from? Although their outcomes in the form of technical innovation are readily observed, the underlying ideas that eventually change the world are often obscured. Here, we develop a novel method that uses deep learning to unearth the markers of prescient ideas from the language used by individuals and groups. Our language-based measure identifies prescient actors and documents that prevailing methods would fail to detect. Applying our model to corpora spanning the disparate worlds of politics, law, and business, we demonstrate that it reliably detects prescient ideas in each domain. Moreover, counter to many prevailing intuitions, prescient ideas emanate from each domain's periphery rather than its core. These findings suggest that the propensity to generate far-sighted ideas may be as much a property of contexts as of individuals.},
  file = {/Users/mstudio/Zotero/storage/KNSH3NC5/Vicinanza et al. - 2023 - A deep-learning model of prescient ideas demonstra.pdf}
}
