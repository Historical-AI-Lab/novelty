{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6daa34-e5c4-4b6a-9b1c-265da69f3c2c",
   "metadata": {},
   "source": [
    "# First Partial Interpretation (1920s - 70s)\n",
    "\n",
    "Nothing here is final, and we don't yet have the 1980s or 90s at all.\n",
    "\n",
    "But we can start to see the basic shape of some results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ffe450-529e-49da-8291-96db6b0b4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dfafe22-411c-4c0e-967c-8196295bef8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial stage:  (303984, 5) (303984, 5)\n",
      "Intermediate stage:  (303984, 8)\n",
      "Final stage should be the same: (303984, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraction_compared</th>\n",
       "      <th>filtered</th>\n",
       "      <th>time_radius</th>\n",
       "      <th>chunks_used</th>\n",
       "      <th>date</th>\n",
       "      <th>num_chunks</th>\n",
       "      <th>precocity</th>\n",
       "      <th>novelty</th>\n",
       "      <th>transience</th>\n",
       "      <th>embed_novelty</th>\n",
       "      <th>embed_transience</th>\n",
       "      <th>embed_precocity</th>\n",
       "      <th>new_cite_count</th>\n",
       "      <th>logcitations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000041afdc91612fa3c16a31e6381b1dfcf5b69b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1959</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.093936</td>\n",
       "      <td>5.733958</td>\n",
       "      <td>5.827894</td>\n",
       "      <td>0.210611</td>\n",
       "      <td>0.210563</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000041afdc91612fa3c16a31e6381b1dfcf5b69b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1959</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.077704</td>\n",
       "      <td>5.808551</td>\n",
       "      <td>5.886255</td>\n",
       "      <td>0.209294</td>\n",
       "      <td>0.208335</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000041afdc91612fa3c16a31e6381b1dfcf5b69b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1959</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.147078</td>\n",
       "      <td>5.724905</td>\n",
       "      <td>5.871983</td>\n",
       "      <td>0.211601</td>\n",
       "      <td>0.210379</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000041afdc91612fa3c16a31e6381b1dfcf5b69b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1959</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.117383</td>\n",
       "      <td>5.595826</td>\n",
       "      <td>5.713209</td>\n",
       "      <td>0.210309</td>\n",
       "      <td>0.207506</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000041afdc91612fa3c16a31e6381b1dfcf5b69b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1959</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.093936</td>\n",
       "      <td>5.733958</td>\n",
       "      <td>5.827894</td>\n",
       "      <td>0.210611</td>\n",
       "      <td>0.210563</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          fraction_compared  filtered  \\\n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b                1.0      True   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b                1.0      True   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b                1.0      True   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b                1.0      True   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b                1.0     False   \n",
       "\n",
       "                                          time_radius  chunks_used  date  \\\n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b           10         1.00  1959   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b           10         0.25  1959   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b           20         1.00  1959   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b           20         0.25  1959   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b           10         1.00  1959   \n",
       "\n",
       "                                          num_chunks  precocity   novelty  \\\n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          11  -0.093936  5.733958   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          11  -0.077704  5.808551   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          11  -0.147078  5.724905   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          11  -0.117383  5.595826   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          11  -0.093936  5.733958   \n",
       "\n",
       "                                          transience  embed_novelty  \\\n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b    5.827894       0.210611   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b    5.886255       0.209294   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b    5.871983       0.211601   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b    5.713209       0.210309   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b    5.827894       0.210611   \n",
       "\n",
       "                                          embed_transience  embed_precocity  \\\n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          0.210563         0.000048   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          0.208335         0.000958   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          0.210379         0.001222   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          0.207506         0.002803   \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b          0.210563         0.000048   \n",
       "\n",
       "                                          new_cite_count  logcitations  \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b               1      0.693147  \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b               1      0.693147  \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b               1      0.693147  \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b               1      0.693147  \n",
       "000041afdc91612fa3c16a31e6381b1dfcf5b69b               1      0.693147  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframe we'll analyze\n",
    "\n",
    "embedding_dfs = []\n",
    "topicmodel_dfs = []\n",
    "\n",
    "for decade in range(20, 80, 10):\n",
    "    e_df = pd.read_csv('precocity_cosine_19' + str(decade) + 's_docs.tsv', sep = '\\t')\n",
    "    tm_df = pd.read_csv('precocity_kld_19' + str(decade) + 's_docs.tsv', sep = '\\t')\n",
    "    embedding_dfs.append(e_df)\n",
    "    topicmodel_dfs.append(tm_df)\n",
    "\n",
    "embeddings = pd.concat(embedding_dfs, axis = 0)\n",
    "topicmodels = pd.concat(topicmodel_dfs, axis = 0)\n",
    "\n",
    "multi_index_columns = ['docid', 'fraction_compared', 'filtered', 'time_radius', 'chunks_used']\n",
    "\n",
    "topicmodels.set_index(multi_index_columns, inplace=True)\n",
    "embeddings.set_index(multi_index_columns, inplace=True)\n",
    "\n",
    "# Rename columns in 'embeddings' DataFrame\n",
    "embeddings.rename(columns={'novelty': 'embed_novelty', \n",
    "                           'transience': 'embed_transience', \n",
    "                           'precocity': 'embed_precocity'}, inplace=True)\n",
    "\n",
    "print('Initial stage: ', embeddings.shape, topicmodels.shape)\n",
    "\n",
    "# Select the columns we want to add from 'embeddings'\n",
    "columns_to_add = ['embed_novelty', 'embed_transience', 'embed_precocity']\n",
    "\n",
    "# Create 'data' DataFrame by joining selected columns from 'embeddings' with 'topicmodels'\n",
    "data = topicmodels.join(embeddings[columns_to_add], how = 'inner')\n",
    "\n",
    "print('Intermediate stage: ', data.shape)\n",
    "\n",
    "data.reset_index(level=['fraction_compared', 'filtered', 'time_radius', 'chunks_used'], inplace=True)\n",
    "\n",
    "meta = pd.read_csv('../metadata/litstudies/LitMetadataWithS2.tsv', sep = '\\t')\n",
    "meta = meta.loc[~pd.isnull(meta.paperId), : ]\n",
    "meta.set_index('paperId', inplace = True)\n",
    "\n",
    "data = data.join(meta['new_cite_count'], how='inner')\n",
    "data['logcitations'] = np.log(data.new_cite_count + 1)\n",
    "\n",
    "print('Final stage should be the same:', data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80d04106-3061-419b-8990-49bf1627c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_topics = []\n",
    "correlation_embeds = []\n",
    "\n",
    "fractions_available = [1.0, 0.05]\n",
    "chunks_available = [1.0, 0.25]\n",
    "\n",
    "for frac in fractions_available:\n",
    "    for chunknum in chunks_available:\n",
    "        df = data.loc[(data.filtered == True) &\n",
    "                      (data.time_radius == 20) &\n",
    "                      (data.fraction_compared == frac) &\n",
    "                      (data.chunks_used == chunknum), :]\n",
    "        correlation_t = pearsonr(df.logcitations, df.precocity)\n",
    "        correlation_e = pearsonr(df.logcitations, df.embed_precocity)\n",
    "        correlation_topics.append(round(correlation_t[0], 3))\n",
    "        correlation_embeds.append(round(correlation_e[0], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c79200c-19ea-4e67-b3b8-9b3f336ff38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Topic model</th>\n",
       "      <th colspan=\"2\" halign=\"left\">GTE Embeds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Compare to all</th>\n",
       "      <th>Most similar 5%</th>\n",
       "      <th>Compare to all</th>\n",
       "      <th>Most similar 5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average all</th>\n",
       "      <td>0.176</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average top 25%</th>\n",
       "      <td>0.199</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Topic model                     GTE Embeds                \n",
       "                Compare to all Most similar 5% Compare to all Most similar 5%\n",
       "Average all              0.176           0.107          0.139           0.105\n",
       "Average top 25%          0.199           0.109          0.151           0.116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guide code borrowed from GPT-4!\n",
    "\n",
    "# Create the DataFrames\n",
    "df_t = pd.DataFrame({\n",
    "    'Compare to all': correlation_topics[:2],\n",
    "    'Most similar 5%': correlation_topics[2:]\n",
    "}, index=['Average all', 'Average top 25%'])\n",
    "\n",
    "df_e = pd.DataFrame({\n",
    "    'Compare to all': correlation_embeds[:2],\n",
    "    'Most similar 5%': correlation_embeds[2:]\n",
    "}, index=['Average all', 'Average top 25%'])\n",
    "\n",
    "# Combine the two DataFrames into a single DataFrame with a multi-level column\n",
    "combined_df = pd.concat([df_t, df_e], axis=1, keys=['Topic model', 'GTE Embeds'])\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be8a0028-a3dd-497d-b9c2-77e05b79be34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Var3=E</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Var3=F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Var3=E       Var3=F      \n",
       "       C     D      C     D\n",
       "A   0.95  0.96   0.92  0.91\n",
       "B   0.89  0.88   0.87  0.85"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 2x2 DataFrame for each state of Var3\n",
    "# Here 'A' and 'B' will be the row indices, and 'C' and 'D' will be the column indices\n",
    "\n",
    "# Define the accuracy statistics for each model configuration\n",
    "# Assuming the order of the stats is the same as the multi-index provided previously\n",
    "accuracy_stats_e = [0.95, 0.89, 0.96, 0.88]  # Stats where Var3 is 'E'\n",
    "accuracy_stats_f = [0.92, 0.87, 0.91, 0.85]  # Stats where Var3 is 'F'\n",
    "\n",
    "# Create the DataFrames\n",
    "df_e = pd.DataFrame({\n",
    "    'C': accuracy_stats_e[:2],\n",
    "    'D': accuracy_stats_e[2:]\n",
    "}, index=['A', 'B'])\n",
    "\n",
    "df_f = pd.DataFrame({\n",
    "    'C': accuracy_stats_f[:2],\n",
    "    'D': accuracy_stats_f[2:]\n",
    "}, index=['A', 'B'])\n",
    "\n",
    "# Combine the two DataFrames into a single DataFrame with a multi-level column\n",
    "combined_df = pd.concat([df_e, df_f], axis=1, keys=['Var3=E', 'Var3=F'])\n",
    "\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7029f-1b33-49cf-b7b1-fc6205ff1ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
